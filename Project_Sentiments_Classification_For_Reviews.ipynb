{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SandySingh72/DATA_Analytics/blob/main/Project_Sentiments_Classification_For_Reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sentiment Classification for Coffee Maker Reviews**"
      ],
      "metadata": {
        "id": "ZXEdb0Op-qmD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement:**\n",
        "\n",
        "1. We are given a dataset \"coffee_maker.csv\" with two columns: \"review\" and \"rating\".\n",
        "2. The task is to classify the reviews as Negative, Neutral, or Positive sentiments based on the following\n",
        "mapping:\n",
        "\n",
        "         • Ratings 1 or 2 are labeled as Negative\n",
        "         • Rating 3 is labeled as Neutral\n",
        "         • Ratings 4 or 5 are labeled as Positive"
      ],
      "metadata": {
        "id": "ME3-iX_c-04b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Stepwise Approach:**"
      ],
      "metadata": {
        "id": "eesQTmTJ_YDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step - 1: Loading of Libraries**"
      ],
      "metadata": {
        "id": "zltsa4hF_tI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "ziga9DtU_3E5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step - 1: Data Loading and Preprocessing:**"
      ],
      "metadata": {
        "id": "AnhZ_puh_dy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Loaded the dataset and removed rows with missing values in \"review\" or \"rating\".\n",
        "2. Converted \"rating\" column to integers.\n",
        "3. Mapped ratings to sentiment labels (\"Negative\", \"Neutral\", \"Positive\")."
      ],
      "metadata": {
        "id": "LoGRdArVAiOO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSprgo7n6l3q"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/coffee_maker.csv') #Load datafile (coffee_maker.csv)\n",
        "df.dropna(subset=['review', 'rating'], inplace=True) #Drop rows under the review and rating column whic\n",
        "df['rating'] = pd.to_numeric(df['rating'], errors='coerce').dropna().astype(int) #Convert the rating to integer form\n",
        "#Relate the value of rating to a grouped value defined as sentiment\n",
        "def map_sentiment(rating):\n",
        "    if rating in [1, 2]:\n",
        "        return 'Negative'\n",
        "    elif rating == 3:\n",
        "        return 'Neutral'\n",
        "    elif rating in [4, 5]:\n",
        "        return 'Positive'\n",
        "df['sentiment'] = df['rating'].apply(map_sentiment)\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step - 2**"
      ],
      "metadata": {
        "id": "E9ohUAoVB6-U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approach 1 – Zero-shot Classification with Pretrained Transformer:\n",
        "\n",
        "1. Used the Hugging Face model \"facebook/bart-large-mnli\".\n",
        "2. Applied zero-shot classi�cation on each review with target labels."
      ],
      "metadata": {
        "id": "CPBD4aCsCYI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\") #Load the classsification model\n",
        "labels = [\"Negative\", \"Neutral\", \"Positive\"] #Provide values of sentiments as labels\n",
        "preds = [classifier(str(text), labels)['labels'][0] for text in tqdm(df['review'])] #Apply classification\n",
        "accuracy = accuracy_score(df['sentiment'], preds) #Calculate the accuracy\n",
        "f1 = f1_score(df['sentiment'], preds, average='weighted')\n",
        "print(f\"Zero-shot Model Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Zero-shot Model F1-score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "WOjXYBvNCiwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train-Test Split:**"
      ],
      "metadata": {
        "id": "9bSaEwJsDGxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used sklearn's train_test_split to divide the data into 70% training and 30% testing."
      ],
      "metadata": {
        "id": "d8Zz9pfVDRm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['review'] #define column for recview\n",
        "y = df['sentiment'] #define column for sentiment\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "Rf5T-HxdDW8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Approach 2 – Sentence Embedding + Logistic Regression:**"
      ],
      "metadata": {
        "id": "puJtyZfuDVUQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Used \"all-MiniLM-L6-v2\" from SentenceTransformers to embed reviews.\n",
        "2. Trained Logistic Regression classifier on embedded vectors."
      ],
      "metadata": {
        "id": "bQOpDy4zDxlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('all-MiniLM-L6-v2') #Load pretrained transformer model\n",
        "#Generate embeddings\n",
        "X_train_emb = model.encode(X_train.tolist(), show_progress_bar=True)\n",
        "X_test_emb = model.encode(X_test.tolist(), show_progress_bar=True)\n",
        "#Train classifier usiing logistic regression\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_emb, y_train)\n",
        "#Predict and evaluate based on the split dataset and trained model\n",
        "y_pred = clf.predict(X_test_emb)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(f\"Custom Classifier Accuracy: {acc:.4f}\")\n",
        "print(f\"Custom Classifier F1-score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "Fy9KVlUbD8Nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Approach 3 – MPNet Embedding + Logistic Regression:**"
      ],
      "metadata": {
        "id": "3z8DLS-LEULA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 1. Used \"all-mpnet-base-v2\" for sentence embedding.\n",
        " 2. Trained Logistic Regression on MPNet embeddings.**"
      ],
      "metadata": {
        "id": "q8Glp1wYE1X-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "#Load more powerful model\n",
        "mpnet_model = SentenceTransformer('all-mpnet-base-v2')"
      ],
      "metadata": {
        "id": "_b01MOwFE5hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate embeddings with mpnet\n",
        "X_train_emb_mpnet = mpnet_model.encode(X_train.tolist(), show_progress_bar=True)\n",
        "X_test_emb_mpnet = mpnet_model.encode(X_test.tolist(), show_progress_bar=True)"
      ],
      "metadata": {
        "id": "sOyQrmveFVna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "metadata": {
        "id": "Q0Qd3NmMFfxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train classifier usinf logisitc regression\n",
        "clf_mpnet = LogisticRegression(max_iter=1000)\n",
        "clf_mpnet.fit(X_train_emb_mpnet, y_train)\n",
        "#Predict\n",
        "y_pred_mpnet = clf_mpnet.predict(X_test_emb_mpnet)\n",
        "acc_mpnet = accuracy_score(y_test, y_pred_mpnet)\n",
        "f1_mpnet = f1_score(y_test, y_pred_mpnet, average='weighted')\n",
        "print(f\"MPNet Classifier Accuracy: {acc_mpnet:.4f}\")\n",
        "print(f\"MPNet Classifier F1-score: {f1_mpnet:.4f}\")"
      ],
      "metadata": {
        "id": "RG3vbEEnFvxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Approach 4 – MPNet Embedding + XGBoost:**"
      ],
      "metadata": {
        "id": "yBzCEwCVGEtt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used MPNet embeddings as input to XGBoost classifier."
      ],
      "metadata": {
        "id": "BhfeykCGGKok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_train_enc = le.fit_transform(y_train)\n",
        "y_test_enc = le.transform(y_test)"
      ],
      "metadata": {
        "id": "LdailYqaGOdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "clf_xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "clf_xgb.fit(X_train_emb_mpnet, y_train_enc)\n",
        "y_pred_xgb = clf_xgb.predict(X_test_emb_mpnet)\n",
        "acc_xgb = accuracy_score(y_test_enc, y_pred_xgb)\n",
        "f1_xgb = f1_score(y_test_enc, y_pred_xgb, average='weighted')\n",
        "print(f\"MPNet + XGBoost Accuracy: {acc_xgb:.4f}\")\n",
        "print(f\"MPNet + XGBoost F1-score: {f1_xgb:.4f}\")"
      ],
      "metadata": {
        "id": "6gb6EMh9GX_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Approach 5 – MPNet Embedding + SVM:**"
      ],
      "metadata": {
        "id": "kHSYMRNhGm8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trained a Support Vector Machine classifier using MPNet embeddings."
      ],
      "metadata": {
        "id": "i9ltn_noGs6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "clf_svm = SVC(kernel='linear')\n",
        "clf_svm.fit(X_train_emb_mpnet, y_train)\n",
        "y_pred_svm = clf_svm.predict(X_test_emb_mpnet)\n",
        "y_pred_svm = clf_svm.predict(X_test_emb_mpnet)\n",
        "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
        "f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
        "print(f\"MPNet + SVM Accuracy: {acc_svm:.4f}\")\n",
        "print(f\"MPNet + SVM F1-score: {f1_svm:.4f}\")"
      ],
      "metadata": {
        "id": "LVQ3iTvSGwM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Comparison of Results:**"
      ],
      "metadata": {
        "id": "cnWovtpfHi_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method.                            Accuracy.   F1 -Score**\n",
        "\n",
        "Zero-shot (BART-large-MNLI)             0.8326        0.8016\n",
        "\n",
        "MiniLM Embedding + Logistic Regression  0.7940        0.7539\n",
        "\n",
        "MPNet Embedding + Logistic Regression   0.8200        0.7795\n",
        "\n",
        "MPNet Embedding + XGBoost               0.8133        0.7730\n",
        "\n",
        "MPNet Embedding + SVM                   0.8207        0.7788"
      ],
      "metadata": {
        "id": "BLyCehrnHleZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion:**"
      ],
      "metadata": {
        "id": "SXpZA3nqIhnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The zero-shot classification using \"facebook/bart-large-mnli\" gave the highest accuracy and F1 score,\n",
        "making it the most suitable option among those tested. Among custom-trained models, MPNet\n",
        "embeddings combined with Logistic Regression or XGBoost also performed competitively and could be\n",
        "further fine-tuned for improvements."
      ],
      "metadata": {
        "id": "46V_oURLIpwn"
      }
    }
  ]
}